# -*- coding: utf-8 -*-
"""chunk encoding data prep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13BG9urj9Bv0n0QEAur_sXUhV2AG3fpiE
"""

!pip install seqeval

"""# Import libraries


"""

import os
import logging
import torch
import numpy as np
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass

from transformers import (
    DistilBertConfig,
    DistilBertForTokenClassification,
    DistilBertTokenizer,
    # AdamW,
    get_linear_schedule_with_warmup,
)
from torch.optim import AdamW
from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler
from torch.nn import CrossEntropyLoss
from seqeval.metrics import f1_score, precision_score, recall_score, classification_report
from tqdm import tqdm
import pandas as pd
from transformers import DistilBertTokenizerFast
from io import StringIO


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

"""# Data"""

with open("drive/MyDrive/exl/data/original/train.txt",'r') as f:
  train_data = f.read()

with open("drive/MyDrive/exl/data/original/test.txt",'r') as f:
  test_data = f.read()

print(test_data[:100])

"""## ETL

### Add agent encoding
"""

# speaker_encoding_dict = {
#     "Agent":"0",
#     "Customer":"1"
# }

# speaker_encoding_dict = {
#     "Agent":"-1",
#     "Customer":"1"
# }

speaker_encoding_dict = {
    "Agent":"0",
    "Customer":"1"
}



def add_speaker_info(text):
  transformed_text = ""
  for chunk in text.split("\n\n"):
    # print(chunk)
    lines = chunk.split("\n")
    # print(len(lines))

    current_speaker = lines[1].split(" ")[0].split(":")[0]
    # print("initial current_speaker",current_speaker)

    transformed_chunk = ''

    for line in lines:
        if 'Agent:' in line or "Customer:" in line:
          speaker = line.split(" ")[0].split(":")[0]
          current_speaker = speaker
          continue
        # print("current_speaker: ",current_speaker)
        speaker_encoding = speaker_encoding_dict[current_speaker]
        processed_line = speaker_encoding + " " +line

        transformed_chunk =  transformed_chunk + "\n" + processed_line

    transformed_text = transformed_text + "\n\n" + transformed_chunk

    # print("original chunk : ")
    # print(chunk)

    # print('-----------------------------------------------------------------------------------')
    # print("transformed chunk : ")

    # print(transformed_chunk)


    # break
  transformed_text = transformed_text.strip()

  while "\n\n\n" in transformed_text:
    transformed_text = transformed_text.replace("\n\n\n","\n\n")
  return transformed_text

transformed_test_data = add_speaker_info(test_data)
print(transformed_test_data)

transformed_train_data = add_speaker_info(train_data)
# print(transformed_test_data)

"""# Add utt id"""

test_calls = transformed_test_data.split("\n\n")
len(test_calls)

train_calls = transformed_train_data.split("\n\n")
len(train_calls)

sample_call = test_calls[0]
print(len(sample_call.split("\n")))
print(sample_call)

def add_utt_id_to_call(text):

  lines = text.split("\n")
  utt_index = 1

  processed_lines = []

  for line in lines:
    speaker_id, token, label = line.split(" ")

    utt_progress_flag = "." in token or "?" in token

    if utt_progress_flag:
      utt_index+=1


    line_with_utt_id = " ".join([
        speaker_id,
        str(utt_index),
        token,
        label
    ])

    processed_lines.append(line_with_utt_id)

  return "\n".join(processed_lines)

print(add_utt_id_to_call(sample_call))

len(add_utt_id_to_call(sample_call).split("\n"))



test_calls_with_uttids = []

for call in test_calls:
  call_with_utt_id = add_utt_id_to_call(call)
  test_calls_with_uttids.append(call_with_utt_id)

# test_data = "\n\n".join(test_calls_with_uttids)

train_calls_with_uttids = []

for call in train_calls:
  call_with_utt_id = add_utt_id_to_call(call)
  train_calls_with_uttids.append(call_with_utt_id)

# train_data = "\n\n".join(calls_with_uttids)

# print(test_data)

# print(train_data)

"""### chunking"""

test_df = pd.read_csv(StringIO(test_data), sep=' ', header=None)
test_df.columns = ['speaker_id','utt_id','text','label']
test_df

train_df = pd.read_csv(StringIO(train_data), sep=' ', header=None)
train_df.columns = ['speaker_id','utt_id','text','label']
train_df

tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")

MAX_LEN = 150
OVERLAP = 30
EFFECTIVE_LEN = MAX_LEN - OVERLAP
SEP = "\n"

def group_utterances(df):
    """
    Groups tokens by speaker_id and utt_id.

    MODIFICATION: Now properly tokenizes each token individually and counts
    the actual BERT subword tokens, not just the original tokens.
    """
    utterances = []


    for (speaker, utt), group in df.groupby(["speaker_id", "utt_id"], sort=False):

        tokens = group["text"].tolist()
        labels = group["label"].tolist()

        # FIXED: Tokenize each token individually to get accurate count
        bert_token_count = 0
        for token in tokens:
            encoded = tokenizer(token, add_special_tokens=False)
            bert_token_count += len(encoded["input_ids"])

        utterances.append({
            "speaker_id": speaker,
            "utt_id": utt,
            "tokens": tokens,  # Original tokens
            "labels": labels,  # Original labels
            "token_count": bert_token_count  # BERT subword count
        })

    return utterances


def split_large_utterance(utt):
    """
    Splits utterances longer than MAX_LEN into smaller chunks.

    MODIFICATION: Now properly handles subword tokenization by tracking
    which original tokens map to which BERT tokens.
    """
    original_tokens = utt["tokens"]
    original_labels = utt["labels"]
    chunks = []

    # Tokenize all tokens and track mappings
    all_bert_tokens = []
    all_bert_labels = []

    for orig_token, orig_label in zip(original_tokens, original_labels):
        encoded = tokenizer(orig_token, add_special_tokens=False)
        bert_pieces = tokenizer.convert_ids_to_tokens(encoded["input_ids"])

        # All subword pieces get the same label as their parent token
        for piece in bert_pieces:
            all_bert_tokens.append(piece)
            all_bert_labels.append(orig_label)

    # Now split into chunks of MAX_LEN
    start = 0
    while start < len(all_bert_tokens):
        piece_tokens = all_bert_tokens[start:start + MAX_LEN]
        piece_labels = all_bert_labels[start:start + MAX_LEN]

        chunks.append([{
            "speaker_id": utt["speaker_id"],
            "utt_id": utt["utt_id"],
            "tokens": piece_tokens,  # BERT tokens
            "labels": piece_labels,
            "token_count": len(piece_tokens)
        }])

        start += EFFECTIVE_LEN

    return chunks


def create_overlap_chunk(chunk):
    """
    Creates overlap from the last OVERLAP tokens of the previous chunk.

    MAJOR MODIFICATION: Skips existing overlap utterances (speaker_id=-1) and only
    uses real utterances to create new overlaps with correct speaker attribution.
    """
    # Flatten all tokens, labels, AND speakers from the chunk
    # IMPORTANT: Skip overlap utterances from previous chunks (speaker_id=-1)
    flat_items = []  # List of (token, label, speaker_id)
    flat_bert_count = 0

    for utt in chunk:
        # Skip overlap utterances - we only want real utterances for creating new overlaps
        if utt["speaker_id"] == -1:
            continue

        # If this is already a BERT-tokenized utterance (from split_large_utterance),
        # we need to handle it differently
        if any(tok.startswith("##") for tok in utt["tokens"]):
            # Already BERT tokens - keep as is
            for tok, lab in zip(utt["tokens"], utt["labels"]):
                flat_items.append((tok, lab, utt["speaker_id"]))
            flat_bert_count += len(utt["tokens"])
        else:
            # Original tokens - keep them as original tokens but count BERT tokens
            for orig_token, orig_label in zip(utt["tokens"], utt["labels"]):
                encoded = tokenizer(orig_token, add_special_tokens=False)
                bert_token_count = len(encoded["input_ids"])

                flat_items.append((orig_token, orig_label, utt["speaker_id"]))
                flat_bert_count += bert_token_count

    # Work backwards to find which original tokens make up the last OVERLAP BERT tokens
    overlap_items = []
    bert_count_so_far = 0

    for i in range(len(flat_items) - 1, -1, -1):
        token, label, speaker = flat_items[i]

        # Count how many BERT tokens this original token produces
        if token.startswith("##"):
            token_bert_count = 1
        else:
            encoded = tokenizer(token, add_special_tokens=False)
            token_bert_count = len(encoded["input_ids"])

        if bert_count_so_far + token_bert_count <= OVERLAP:
            overlap_items.insert(0, (token, label, speaker))
            bert_count_so_far += token_bert_count
        else:
            break

    # Group consecutive tokens by speaker to create multiple utterances if needed
    overlap_utterances = []
    if overlap_items:
        current_speaker = overlap_items[0][2]
        current_tokens = [overlap_items[0][0]]
        current_labels = [overlap_items[0][1]]
        current_count = 1 if overlap_items[0][0].startswith("##") else len(tokenizer(overlap_items[0][0], add_special_tokens=False)["input_ids"])

        for token, label, speaker in overlap_items[1:]:
            if speaker == current_speaker:
                # Same speaker, add to current utterance
                current_tokens.append(token)
                current_labels.append(label)
                token_count = 1 if token.startswith("##") else len(tokenizer(token, add_special_tokens=False)["input_ids"])
                current_count += token_count
            else:
                # Speaker changed, save current and start new
                overlap_utterances.append({
                    "speaker_id": current_speaker,
                    "utt_id": -1,
                    "tokens": current_tokens,
                    "labels": current_labels,
                    "token_count": current_count
                })
                current_speaker = speaker
                current_tokens = [token]
                current_labels = [label]
                current_count = 1 if token.startswith("##") else len(tokenizer(token, add_special_tokens=False)["input_ids"])

        # Add the last group
        overlap_utterances.append({
            "speaker_id": current_speaker,
            "utt_id": -1,
            "tokens": current_tokens,
            "labels": current_labels,
            "token_count": current_count
        })

    return overlap_utterances if overlap_utterances else []

def chunk_utterances(utterances):
    """
    Chunks utterances into sequences of MAX_LEN tokens with OVERLAP.

    MODIFICATION: Updated token counting logic to handle both original
    and BERT-tokenized utterances correctly.
    """
    chunks = []
    current_chunk = []
    current_token_count = 0

    i = 0
    while i < len(utterances):
        utt = utterances[i]

        # Force-split long utterances
        if utt["token_count"] > MAX_LEN:
            # If current chunk exists, save it first
            if current_chunk:
                chunks.append(current_chunk)
                current_chunk = []
                current_token_count = 0

            # Add split chunks
            long_chunks = split_large_utterance(utt)
            chunks.extend(long_chunks)
            i += 1
            continue

        # Check if current utterance fits in the chunk
        if current_token_count + utt["token_count"] > MAX_LEN:
            # Save full chunk
            if current_chunk:
                chunks.append(current_chunk)

                # Build next chunk using overlap
                current_chunk = create_overlap_chunk(current_chunk)
                current_token_count = current_chunk[0]["token_count"]
            else:
                # Should never happen, but safe guard
                i += 1
                continue

        # Add utterance normally
        current_chunk.append(utt)
        current_token_count += utt["token_count"]
        i += 1

    # Add the final chunk
    if current_chunk:
        chunks.append(current_chunk)

    return chunks


def chunks_to_string(chunks):
    """
    Converts chunks into annotation format with Agent:/Customer: prefixes.

    MODIFICATION: Forces speaker prefix at the start of every chunk, then adds
    prefixes when speaker changes within the chunk.
    """
    output_lines = []

    for chunk_idx, chunk in enumerate(chunks):
        chunk_lines = []
        last_speaker = None

        # Debug: print what we're getting
        # print(f"\n=== CHUNK {chunk_idx} ===")
        # for i, utt in enumerate(chunk):
        #     print(f"Utterance {i}: speaker_id={utt['speaker_id']}, tokens={utt['tokens'][:3]}...")

        for utt in chunk:
            current_speaker = utt["speaker_id"]

            # Add speaker prefix if speaker is valid and (first in chunk OR changed)
            if current_speaker in [0, 1]:
                if last_speaker is None or current_speaker != last_speaker:
                    if current_speaker == 0:
                        chunk_lines.append("Agent: O")
                    elif current_speaker == 1:
                        chunk_lines.append("Customer: O")
                    last_speaker = current_speaker
            else:
                # This shouldn't happen - overlap should have real speaker IDs now
                print(f"WARNING: Found speaker_id={current_speaker} (should be 0 or 1)")

            # Add tokens
            for tok, lab in zip(utt["tokens"], utt["labels"]):
                chunk_lines.append(f"{tok} {lab}")

        # Add chunk to output
        output_lines.extend(chunk_lines)
        output_lines.append("")  # Blank line between chunks

    return "\n".join(output_lines)

def add_chunk_id(text):

  chunks = text.split("\n\n")
  chunks_with_ids = []
  num_chunks = len(chunks)

  for i, chunk in enumerate(chunks):
    # chunk_id = int(np.round((i*100)/num_chunks))
    chunk_id = int(np.round((i * 100) / (num_chunks - 1))) if num_chunks > 1 else 0
    chunk_with_id = "chunk_"+str(chunk_id) + " O\n" + chunk
    chunks_with_ids.append(chunk_with_id)

  return "\n\n".join(chunks_with_ids)

# def group_utterances(df):
#     """
#     Groups tokens by speaker_id and utt_id.

#     MODIFICATION: Now properly tokenizes each token individually and counts
#     the actual BERT subword tokens, not just the original tokens.
#     """
#     utterances = []

#     try:

#       for (speaker, utt), group in df.groupby(["speaker_id", "utt_id"], sort=False):

#           tokens = group["text"].tolist()
#           labels = group["label"].tolist()

#           # FIXED: Tokenize each token individually to get accurate count
#           bert_token_count = 0
#           for token in tokens:
#               encoded = tokenizer(token, add_special_tokens=False)
#               bert_token_count += len(encoded["input_ids"])

#           utterances.append({
#               "speaker_id": speaker,
#               "utt_id": utt,
#               "tokens": tokens,  # Original tokens
#               "labels": labels,  # Original labels
#               "token_count": bert_token_count  # BERT subword count
#           })
#     except Exception as err:
#         print(tokens)
#         print(Exception)


#     return utterances

def run_chunking_for_single_call(call_data):


  call_df = pd.read_csv(StringIO(call_data), sep=' ', header=None)

  call_df.columns = ['speaker_id','utt_id','text','label']
  # call_df['n_index'] = call_df.index

  # print(call_df.isna().sum())
  call_df.text=call_df.text.fillna("None")

  # print(call_df[call_df.text.isna()].n_index.tolist()[0])

  # print(1)
  utterances = group_utterances(call_df)
  # print(2)
  chunked = chunk_utterances(utterances)
  # print(3)
  annotation_text = chunks_to_string(chunked)
  # print(4)
  annotation_text = add_chunk_id(annotation_text)

  return annotation_text

c = run_chunking_for_single_call(train_calls_with_uttids[86])
len(c.split("\n\n"))

print(train_calls_with_uttids[86])



train_calls_with_uttids[86].isna().sum()

print(c.split("\n\n")[1])

test_annotation_text = ""

for call_data in test_calls_with_uttids:
  call_data_chunked = run_chunking_for_single_call(call_data)
  test_annotation_text = test_annotation_text + "\n\n" + call_data_chunked

print(test_calls_with_uttids[0])

# run_chunking_for_single_call(train_calls_with_uttids[86])

train_annotation_text = ""

for i, call_data in enumerate(train_calls_with_uttids):

  try:
  # print(type(call_data))
    call_data_chunked = run_chunking_for_single_call(call_data)
    train_annotation_text = train_annotation_text + "\n\n" + call_data_chunked

  except Exception as err:
    print(err)
    # print(call_data)
    print(type(call_data))
    print(i)

print(train_annotation_text)

while "\n\n\n" in train_annotation_text:
  train_annotation_text = train_annotation_text.replace("\n\n\n","\n\n")

while "\n\n\n" in test_annotation_text:
  test_annotation_text = test_annotation_text.replace("\n\n\n","\n\n")

print(test_annotation_text)

"""### Add chunk encodings"""

train_annotation_text_with_speaker = add_speaker_info(train_annotation_text.strip())
print(train_annotation_text_with_speaker)

test_annotation_text_with_speaker = add_speaker_info(test_annotation_text.strip())
print(test_annotation_text_with_speaker)

def add_chunk_encoding(text):
  transformed_text = ""
  for chunk in text.split("\n\n"):
    # print(chunk)
    lines = chunk.split("\n")
    # print(len(lines))

    current_chunk= lines[0].split(" ")[1]

    chunk_id = current_chunk.split("_")[-1]
    # print(chunk_id)

    lines_without_chunk = lines[1:]
    processed_lines = []

    for line in lines_without_chunk:
      speaker_id, token, label = line.split(" ")
      processed_line =  " ".join([
          chunk_id,
          speaker_id,
          token,
          label
      ])

      processed_lines.append(processed_line)
    processed_chunk = "\n".join(processed_lines)
    processed_chunk = processed_chunk.strip()

    transformed_text = transformed_text + "\n\n" + processed_chunk

  return transformed_text.strip()


    # print("initial current_chunk",current_chunk)

    # transformed_chunk = ''

    # for line in lines:
    #     if 'Agent:' in line or "Customer:" in line:
    #       speaker = line.split(" ")[0].split(":")[0]
    #       current_speaker = speaker
    #       continue
    #     # print("current_speaker: ",current_speaker)
    #     speaker_encoding = speaker_encoding_dict[current_speaker]
    #     processed_line = speaker_encoding + " " +line

    #     transformed_chunk =  transformed_chunk + "\n" + processed_line

    # transformed_text = transformed_text + "\n\n" + transformed_chunk

print(add_chunk_encoding(test_annotation_text_with_speaker))

"""### Add chunk encoding"""



test_annotation_text_with_speaker_and_chunk = add_chunk_encoding(test_annotation_text_with_speaker)

train_annotation_text_with_speaker_and_chunk = add_chunk_encoding(train_annotation_text_with_speaker)

"""### Save data"""

with open("drive/MyDrive/exl/data/chunk_encoding/train.txt",'w+') as f:
  f.write(train_annotation_text_with_speaker_and_chunk)

with open("drive/MyDrive/exl/data/chunk_encoding/test.txt",'w+') as f:
  f.write(test_annotation_text_with_speaker_and_chunk)

###

