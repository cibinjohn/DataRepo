# -*- coding: utf-8 -*-
"""distilbert chunk encoding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q7iE0NmndmDc7sOkUKFSCx0JF7o9cRKT
"""

pip install seqeval

import os
import logging
import torch
import numpy as np
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass
from transformers import (
    DistilBertConfig,
    DistilBertForTokenClassification,
    DistilBertTokenizer,
    get_linear_schedule_with_warmup,
)
from torch.optim import AdamW
from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler
from torch.nn import CrossEntropyLoss
from seqeval.metrics import f1_score, precision_score, recall_score, classification_report
from tqdm import tqdm

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class Config:
    """Configuration for DistilBERT model training"""
    model_name: str = "distilbert-base-cased"
    max_seq_length: int = 256
    batch_size: int = 8
    learning_rate: float = 5e-5
    num_epochs: int = 10
    weight_decay: float = 0.0
    warmup_steps: int = 0
    adam_epsilon: float = 1e-8
    max_grad_norm: float = 1.0
    seed: int = 42

"""# Utility functions"""
class InputExample:
    """A single training/test example for token classification"""
    def __init__(self, guid: str, words: List[str], labels: List[str],
                 speaker_ids: List[int] = None, chunk_ids: List[int] = None):
        self.guid = guid
        self.words = words
        self.labels = labels
        self.speaker_ids = speaker_ids if speaker_ids is not None else [0] * len(words)
        self.chunk_ids = chunk_ids if chunk_ids is not None else [0] * len(words)

class InputFeatures:
    """A single set of features of data"""
    def __init__(self, input_ids, attention_mask, label_ids, speaker_ids, chunk_ids):
        self.input_ids = input_ids
        self.attention_mask = attention_mask
        self.label_ids = label_ids
        self.speaker_ids = speaker_ids
        self.chunk_ids = chunk_ids

class DistilBertForTokenClassificationWithSpeakerAndChunk(DistilBertForTokenClassification):
    """DistilBERT with speaker and chunk embeddings for token classification

    Architecture: Speaker and chunk embeddings are added to the input embeddings BEFORE
    passing through DistilBERT, similar to how positional embeddings work in transformers.
    """

    def __init__(self, config, num_speakers=3, num_chunks=101):
        super().__init__(config)
        self.num_speakers = num_speakers
        self.num_chunks = num_chunks

        # Add speaker embedding layer
        # Speaker embeddings have the same dimension as word embeddings
        self.speaker_embeddings = torch.nn.Embedding(
            num_speakers,
            config.dim  # DistilBERT hidden size (768 for base model)
        )

        # Add chunk embedding layer
        self.chunk_embeddings = torch.nn.Embedding(
            num_chunks,
            config.dim
        )

        # Initialize embeddings
        self.speaker_embeddings.weight.data.normal_(mean=0.0, std=config.initializer_range)
        self.chunk_embeddings.weight.data.normal_(mean=0.0, std=config.initializer_range)

    def forward(
        self,
        input_ids=None,
        attention_mask=None,
        labels=None,
        speaker_ids=None,
        chunk_ids=None,
        **kwargs
    ):
        # Get word embeddings from DistilBERT's embeddings layer
        inputs_embeds = self.distilbert.embeddings.word_embeddings(input_ids)

        # Add speaker embeddings to word embeddings BEFORE passing to DistilBERT
        if speaker_ids is not None:
            speaker_embeds = self.speaker_embeddings(speaker_ids)
            inputs_embeds = inputs_embeds + speaker_embeds

        # Add chunk embeddings
        if chunk_ids is not None:
            chunk_embeds = self.chunk_embeddings(chunk_ids)
            inputs_embeds = inputs_embeds + chunk_embeds

        # Pass combined embeddings through DistilBERT
        # Note: We pass inputs_embeds instead of input_ids
        outputs = self.distilbert(
            inputs_embeds=inputs_embeds,
            attention_mask=attention_mask
        )

        sequence_output = outputs[0]

        # Use DistilBERT's original classifier
        sequence_output = self.dropout(sequence_output)
        logits = self.classifier(sequence_output)

        loss = None
        if labels is not None:
            loss_fct = torch.nn.CrossEntropyLoss()
            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))

        return (loss, logits) if loss is not None else (logits,)

"""# Training Class"""
class DistilBertNERTraining:
    """
    Class for training DistilBERT-based NER models with speaker and chunk embeddings
    DistilBERT is 40% smaller and 60% faster than BERT while retaining 97% of performance
    """

    def __init__(
        self,
        labels: List[str],
        model_save_dir: str,
        config: Optional[Config] = None,
        device: Optional[str] = None
    ):
        """
        Initialize the training class

        Args:
            labels: List of NER labels (e.g., ['O', 'Authentication'])
            model_save_dir: Directory to save the trained model
            config: Training configuration
            device: Device to use for training ('cuda' or 'cpu')
        """
        self.labels = labels
        self.label_map = {label: i for i, label in enumerate(labels)}
        self.num_labels = len(labels)
        self.model_save_dir = model_save_dir
        self.config = config or Config()

        # Set device
        if device:
            self.device = torch.device(device)
        else:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # Padding label ID
        self.pad_token_label_id = CrossEntropyLoss().ignore_index

        # Special IDs for padding and special tokens
        self.pad_speaker_id = 2
        self.pad_chunk_id = 101

        # Track training history
        self.train_loss_history = []
        self.best_train_loss = float('inf')
        self.best_model_path = None

        # Initialize model and tokenizer as None
        self.model = None
        self.tokenizer = None

        # Set random seed for reproducibility
        self._set_seed()

        logger.info(f"Initialized DistilBertNERTraining with {self.num_labels} labels")
        logger.info(f"Device: {self.device}")
        logger.info(f"Model: {self.config.model_name}")
        logger.info(f"Pad speaker ID: {self.pad_speaker_id}")
        logger.info(f"Pad chunk ID: {self.pad_chunk_id}")

    def _set_seed(self):
        """Set random seed for reproducibility"""
        import random
        random.seed(self.config.seed)
        np.random.seed(self.config.seed)
        torch.manual_seed(self.config.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(self.config.seed)

    def load_pretrained_model(self, num_speakers=3, num_chunks=101):
        """Load pretrained DistilBERT model and tokenizer with speaker and chunk embeddings

        Args:
            num_speakers: Number of speaker IDs (default 3: speaker 0, speaker 1, and padding ID 2)
            num_chunks: Number of chunk IDs (default 101: chunks 0-100)
        """
        logger.info(f"Loading pretrained DistilBERT model: {self.config.model_name}")

        # Load tokenizer
        self.tokenizer = DistilBertTokenizer.from_pretrained(
            self.config.model_name,
            do_lower_case=False
        )

        # Load model configuration
        model_config = DistilBertConfig.from_pretrained(
            self.config.model_name,
            num_labels=self.num_labels
        )

        # Load base model first
        base_model = DistilBertForTokenClassification.from_pretrained(
            self.config.model_name,
            config=model_config
        )

        # Create custom model with speaker and chunk embeddings
        self.model = DistilBertForTokenClassificationWithSpeakerAndChunk(
            config=model_config,
            num_speakers=num_speakers,
            num_chunks=num_chunks
        )

        # Copy weights from base model
        self.model.distilbert = base_model.distilbert
        self.model.classifier = base_model.classifier
        self.model.dropout = base_model.dropout

        self.model.to(self.device)
        logger.info(f"DistilBERT model with speaker and chunk embeddings loaded successfully")
        logger.info(f"  num_speakers={num_speakers}, num_chunks={num_chunks}")

    def load_saved_model(self, model_dir: Optional[str] = None, num_speakers=3, num_chunks=101):
        """Load a previously saved model

        Args:
            model_dir: Directory where the model was saved (defaults to self.model_save_dir)
            num_speakers: Number of speaker IDs (default 3)
            num_chunks: Number of chunk IDs (default 101)
        """
        if model_dir is None:
            model_dir = self.model_save_dir

        logger.info(f"Loading saved model from: {model_dir}")

        if not os.path.exists(model_dir):
            raise ValueError(f"Model directory does not exist: {model_dir}")

        # Load tokenizer
        self.tokenizer = DistilBertTokenizer.from_pretrained(model_dir)

        # Load labels if they exist
        labels_file = os.path.join(model_dir, "labels.txt")
        if os.path.exists(labels_file):
            with open(labels_file, 'r') as f:
                loaded_labels = [line.strip() for line in f if line.strip()]

            # Update labels and label map
            if loaded_labels != self.labels:
                logger.warning(f"Loaded labels differ from initialized labels. Using loaded labels.")
                self.labels = loaded_labels
                self.label_map = {label: i for i, label in enumerate(self.labels)}
                self.num_labels = len(self.labels)

        # Load model configuration
        model_config = DistilBertConfig.from_pretrained(model_dir)

        # Create custom model with speaker and chunk embeddings
        self.model = DistilBertForTokenClassificationWithSpeakerAndChunk(
            config=model_config,
            num_speakers=num_speakers,
            num_chunks=num_chunks
        )

        # Load the saved state dict
        state_dict = torch.load(os.path.join(model_dir, "pytorch_model.bin"), map_location=self.device)
        self.model.load_state_dict(state_dict)

        self.model.to(self.device)
        logger.info(f"Model loaded successfully from {model_dir}")

    def _read_examples_from_file(self, file_path: str, mode: str = "train") -> List[InputExample]:
        """
        Read examples from a CoNLL-format file with chunk IDs and speaker IDs
        Expected format: chunk_id speaker_id token label

        Args:
            file_path: Path to the input file
            mode: Mode indicator (train/dev/test)

        Returns:
            List of InputExample objects
        """
        examples = []
        guid_index = 1

        with open(file_path, 'r', encoding='utf-8') as f:
            words = []
            labels = []
            speaker_ids = []
            chunk_ids = []

            for line_num, line in enumerate(f, 1):
                line = line.strip()

                if line.startswith("-DOCSTART-") or line == "":
                    if words:
                        examples.append(InputExample(
                            guid=f"{mode}-{guid_index}",
                            words=words,
                            labels=labels,
                            speaker_ids=speaker_ids,
                            chunk_ids=chunk_ids
                        ))
                        guid_index += 1
                        words = []
                        labels = []
                        speaker_ids = []
                        chunk_ids = []
                else:
                    splits = line.split()

                    assert len(splits) ==4
                    if len(splits) >= 4:  # chunk_id, speaker_id, token, label
                        try:
                            chunk_ids.append(int(splits[0]))
                            speaker_ids.append(int(splits[1]))
                            words.append(splits[2])
                            labels.append(splits[3])
                        except ValueError as e:
                            logger.warning(f"Line {line_num}: Could not parse IDs as integers. Line: {line}")
                    elif len(splits) == 3:  # Old format: speaker_id, token, label
                        logger.warning(f"Line {line_num}: Only 3 columns found (missing chunk_id). Defaulting to chunk_id=0. Line: {line}")
                        chunk_ids.append(0)
                        speaker_ids.append(int(splits[0]))
                        words.append(splits[1])
                        labels.append(splits[2])
                    elif len(splits) == 2:  # Minimal format: token, label
                        logger.warning(f"Line {line_num}: Only 2 columns found. Defaulting to chunk_id=0, speaker_id=0. Line: {line}")
                        chunk_ids.append(0)
                        speaker_ids.append(0)
                        words.append(splits[0])
                        labels.append(splits[1])
                    elif len(splits) > 0:
                        logger.warning(f"Line {line_num}: Unexpected format. Found {len(splits)} columns. Line: {line}")

            # Add last example if exists
            if words:
                examples.append(InputExample(
                    guid=f"{mode}-{guid_index}",
                    words=words,
                    labels=labels,
                    speaker_ids=speaker_ids,
                    chunk_ids=chunk_ids
                ))

        logger.info(f"Read {len(examples)} examples from {file_path}")
        if len(examples) == 0:
            logger.error(f"No examples were read from {file_path}. Please check the file format.")
            logger.error("Expected format: 'chunk_id speaker_id token label' (4 columns separated by spaces)")
        return examples

    def _convert_examples_to_features(
        self,
        examples: List[InputExample]
    ) -> List[InputFeatures]:
        """
        Convert examples to features suitable for DistilBERT with speaker and chunk embeddings

        Args:
            examples: List of InputExample objects

        Returns:
            List of InputFeatures objects
        """
        features = []

        for ex_index, example in enumerate(tqdm(examples, desc="Converting examples")):
            tokens = []
            label_ids = []
            speaker_token_ids = []
            chunk_token_ids = []

            # Tokenize each word and align labels, speaker IDs, and chunk IDs
            for word, label, speaker_id, chunk_id in zip(example.words, example.labels,
                                                          example.speaker_ids, example.chunk_ids):
                word_tokens = self.tokenizer.tokenize(word)

                if len(word_tokens) > 0:
                    tokens.extend(word_tokens)
                    # Use the real label for the first token, pad for others
                    label_ids.extend([self.label_map[label]] +
                                   [self.pad_token_label_id] * (len(word_tokens) - 1))
                    # Extend speaker IDs for all subword tokens
                    speaker_token_ids.extend([speaker_id] * len(word_tokens))
                    # Extend chunk IDs for all subword tokens
                    chunk_token_ids.extend([chunk_id] * len(word_tokens))

            # Truncate if necessary
            max_length = self.config.max_seq_length - 2  # Account for [CLS] and [SEP]
            if len(tokens) > max_length:
                tokens = tokens[:max_length]
                label_ids = label_ids[:max_length]
                speaker_token_ids = speaker_token_ids[:max_length]
                chunk_token_ids = chunk_token_ids[:max_length]

            # Add special tokens - use pad IDs for special tokens
            tokens = [self.tokenizer.cls_token] + tokens + [self.tokenizer.sep_token]
            label_ids = [self.pad_token_label_id] + label_ids + [self.pad_token_label_id]
            speaker_token_ids = [self.pad_speaker_id] + speaker_token_ids + [self.pad_speaker_id]
            chunk_token_ids = [self.pad_chunk_id] + chunk_token_ids + [self.pad_chunk_id]

            # Convert tokens to IDs
            input_ids = self.tokenizer.convert_tokens_to_ids(tokens)

            # Create attention mask
            attention_mask = [1] * len(input_ids)

            # Pad to max length - use pad IDs for padding
            padding_length = self.config.max_seq_length - len(input_ids)
            input_ids += [self.tokenizer.pad_token_id] * padding_length
            attention_mask += [0] * padding_length
            label_ids += [self.pad_token_label_id] * padding_length
            speaker_token_ids += [self.pad_speaker_id] * padding_length
            chunk_token_ids += [self.pad_chunk_id] * padding_length

            assert len(input_ids) == self.config.max_seq_length
            assert len(attention_mask) == self.config.max_seq_length
            assert len(label_ids) == self.config.max_seq_length
            assert len(speaker_token_ids) == self.config.max_seq_length
            assert len(chunk_token_ids) == self.config.max_seq_length

            features.append(InputFeatures(
                input_ids=input_ids,
                attention_mask=attention_mask,
                label_ids=label_ids,
                speaker_ids=speaker_token_ids,
                chunk_ids=chunk_token_ids
            ))

        return features

    def _create_dataloader(
        self,
        features: List[InputFeatures],
        shuffle: bool = False
    ) -> DataLoader:
        """
        Create a DataLoader from features

        Args:
            features: List of InputFeatures
            shuffle: Whether to shuffle the data

        Returns:
            DataLoader object
        """
        all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)
        all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)
        all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)
        all_speaker_ids = torch.tensor([f.speaker_ids for f in features], dtype=torch.long)
        all_chunk_ids = torch.tensor([f.chunk_ids for f in features], dtype=torch.long)

        dataset = TensorDataset(all_input_ids, all_attention_mask, all_label_ids,
                               all_speaker_ids, all_chunk_ids)

        sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)
        dataloader = DataLoader(dataset, sampler=sampler, batch_size=self.config.batch_size)

        return dataloader

    def train(self, train_file: str, dev_file: Optional[str] = None):
        """
        Train the model

        Args:
            train_file: Path to training data file
            dev_file: Optional path to development/validation data file
        """
        if self.model is None or self.tokenizer is None:
            raise ValueError("Model not loaded. Call load_pretrained_model() first.")

        logger.info("Starting training...")

        # Load and prepare training data
        train_examples = self._read_examples_from_file(train_file, mode="train")
        train_features = self._convert_examples_to_features(train_examples)
        train_dataloader = self._create_dataloader(train_features, shuffle=True)

        # Calculate total training steps
        num_train_steps = len(train_dataloader) * self.config.num_epochs

        # Prepare optimizer and scheduler
        no_decay = ["bias", "LayerNorm.weight"]
        optimizer_grouped_parameters = [
            {
                "params": [p for n, p in self.model.named_parameters()
                          if not any(nd in n for nd in no_decay)],
                "weight_decay": self.config.weight_decay,
            },
            {
                "params": [p for n, p in self.model.named_parameters()
                          if any(nd in n for nd in no_decay)],
                "weight_decay": 0.0,
            },
        ]

        optimizer = AdamW(
            optimizer_grouped_parameters,
            lr=self.config.learning_rate,
            eps=self.config.adam_epsilon
        )

        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=self.config.warmup_steps,
            num_training_steps=num_train_steps
        )

        # Training loop
        logger.info(f"***** Running training *****")
        logger.info(f"  Num examples = {len(train_examples)}")
        logger.info(f"  Num epochs = {self.config.num_epochs}")
        logger.info(f"  Batch size = {self.config.batch_size}")
        logger.info(f"  Total optimization steps = {num_train_steps}")

        global_step = 0
        train_loss = 0.0

        self.model.zero_grad()

        for epoch in range(self.config.num_epochs):
            logger.info(f"Epoch {epoch + 1}/{self.config.num_epochs}")

            self.model.train()
            epoch_loss = 0.0

            for step, batch in enumerate(tqdm(train_dataloader, desc="Training")):
                batch = tuple(t.to(self.device) for t in batch)

                inputs = {
                    "input_ids": batch[0],
                    "attention_mask": batch[1],
                    "labels": batch[2],
                    "speaker_ids": batch[3],
                    "chunk_ids": batch[4]
                }

                outputs = self.model(**inputs)
                loss = outputs[0]

                loss.backward()

                train_loss += loss.item()
                epoch_loss += loss.item()

                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(),
                    self.config.max_grad_norm
                )

                optimizer.step()
                scheduler.step()
                self.model.zero_grad()
                global_step += 1

            avg_epoch_loss = epoch_loss / len(train_dataloader)
            self.train_loss_history.append(avg_epoch_loss)
            logger.info(f"Epoch {epoch + 1} - Average loss: {avg_epoch_loss:.4f}")

            # Save best model
            if avg_epoch_loss < self.best_train_loss:
                self.best_train_loss = avg_epoch_loss
                self.best_model_path = os.path.join(self.model_save_dir, "best_model")
                self.save_model(self.best_model_path)
                logger.info(f"New best model saved with loss: {avg_epoch_loss:.4f}")

            # Evaluate on dev set if provided
            if dev_file:
                dev_metrics, _ = self.evaluate(dev_file, return_predictions=False)
                logger.info(f"Dev metrics - Precision: {dev_metrics['precision']:.4f}, "
                          f"Recall: {dev_metrics['recall']:.4f}, F1: {dev_metrics['f1']:.4f}")

        # Save last model
        last_model_path = os.path.join(self.model_save_dir, "last_model")
        self.save_model(last_model_path)
        logger.info(f"Last model saved to {last_model_path}")

        avg_train_loss = train_loss / global_step
        logger.info(f"Training completed. Average training loss: {avg_train_loss:.4f}")

    def evaluate(self, eval_file: str, return_predictions: bool = True) -> Tuple[Dict[str, float], Optional[str]]:
        """
        Evaluate the model

        Args:
            eval_file: Path to evaluation data file
            return_predictions: If True, return predictions text along with metrics

        Returns:
            Tuple of (metrics_dict, predictions_text)
            - metrics_dict: Dictionary containing evaluation metrics
            - predictions_text: String with "chunk_id speaker_id token prediction" format (None if return_predictions=False)
        """
        if self.model is None or self.tokenizer is None:
            raise ValueError("Model not loaded.")

        logger.info("Running evaluation...")

        # Load and prepare evaluation data
        eval_examples = self._read_examples_from_file(eval_file, mode="eval")
        eval_features = self._convert_examples_to_features(eval_examples)
        eval_dataloader = self._create_dataloader(eval_features, shuffle=False)

        # Evaluation
        self.model.eval()
        eval_loss = 0.0
        nb_eval_steps = 0
        preds = None
        out_label_ids = None

        for batch in tqdm(eval_dataloader, desc="Evaluating"):
            batch = tuple(t.to(self.device) for t in batch)

            with torch.no_grad():
                inputs = {
                    "input_ids": batch[0],
                    "attention_mask": batch[1],
                    "labels": batch[2],
                    "speaker_ids": batch[3],
                    "chunk_ids": batch[4]
                }

                outputs = self.model(**inputs)
                tmp_eval_loss, logits = outputs[:2]

                eval_loss += tmp_eval_loss.item()

            nb_eval_steps += 1

            if preds is None:
                preds = logits.detach().cpu().numpy()
                out_label_ids = inputs["labels"].detach().cpu().numpy()
            else:
                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)
                out_label_ids = np.append(
                    out_label_ids,
                    inputs["labels"].detach().cpu().numpy(),
                    axis=0
                )

        eval_loss = eval_loss / nb_eval_steps
        preds = np.argmax(preds, axis=2)

        # Convert IDs to labels
        id_to_label = {i: label for label, i in self.label_map.items()}

        out_label_list = []
        preds_list = []

        for i in range(out_label_ids.shape[0]):
            temp_out = []
            temp_pred = []
            for j in range(out_label_ids.shape[1]):
                if out_label_ids[i, j] != self.pad_token_label_id:
                    temp_out.append(id_to_label[out_label_ids[i][j]])
                    temp_pred.append(id_to_label[preds[i][j]])
            out_label_list.append(temp_out)
            preds_list.append(temp_pred)

        # Calculate metrics
        results = {
            "loss": eval_loss,
            "precision": precision_score(out_label_list, preds_list),
            "recall": recall_score(out_label_list, preds_list),
            "f1": f1_score(out_label_list, preds_list),
        }

        # Print detailed classification report
        logger.info("\nClassification Report:")
        logger.info("\n" + classification_report(out_label_list, preds_list))

        # Generate predictions text if requested
        predictions_text = None
        if return_predictions:
            # Read original tokens, speaker IDs, and chunk IDs from file
            original_data = []
            with open(eval_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("-DOCSTART-") or line == "":
                        if original_data:
                            original_data.append(("", "", "", ""))  # Empty line between sentences
                    else:
                        splits = line.split()
                        if len(splits) >= 4:
                            original_data.append((splits[0], splits[1], splits[2], splits[3]))
                        elif len(splits) == 3:
                            original_data.append(("0", splits[0], splits[1], splits[2]))
                        elif len(splits) == 2:
                            original_data.append(("0", "0", splits[0], splits[1]))

            # Flatten predictions list
            flat_predictions = []
            for sent_preds in preds_list:
                flat_predictions.extend(sent_preds)
                flat_predictions.append("")  # Empty line between sentences

            # Create predictions text with chunk_id speaker_id token prediction format
            predictions_lines = []
            pred_idx = 0

            for chunk_id, speaker_id, token, label in original_data:
                if token == "":
                    predictions_lines.append("")
                else:
                    if pred_idx < len(flat_predictions) and flat_predictions[pred_idx] != "":
                        predictions_lines.append(f"{chunk_id} {speaker_id} {token} {flat_predictions[pred_idx]}")
                        pred_idx += 1
                    else:
                        predictions_lines.append(f"{chunk_id} {speaker_id} {token} O")
                        if pred_idx < len(flat_predictions):
                            pred_idx += 1

            predictions_text = "\n".join(predictions_lines)

        return results, predictions_text

    def save_model(self, model_save_dir):
        """Save the trained model and tokenizer"""
        logger.info(f"Saving model to {model_save_dir}")

        if not os.path.exists(model_save_dir):
            os.makedirs(model_save_dir)

        # Save tokenizer
        self.tokenizer.save_pretrained(model_save_dir)

        # Save model
        self.model.save_pretrained(model_save_dir)

        # Save labels
        labels_file = os.path.join(model_save_dir, "labels.txt")
        with open(labels_file, 'w') as f:
            f.write('\n'.join(self.labels))

        logger.info("Model saved successfully")

    def plot_training_loss(self, save_path: Optional[str] = None):
        """Plot training loss over epochs

        Args:
            save_path: Optional path to save the plot image
        """
        import matplotlib.pyplot as plt

        if not self.train_loss_history:
            logger.warning

import matplotlib.pyplot as plt
def plot_training_loss(losses):
  epochs = range(1, len(losses)+1)

  plt.figure()
  plt.plot(epochs, losses)
  plt.xlabel("Epoch")
  plt.ylabel("Loss")
  plt.title("Epoch vs loss")
  plt.show()

# Define labels
labels = ['O', 'Authentication']

# Create configuration
config = Config(
    model_name="distilbert-base-cased",
    max_seq_length=256,
    batch_size=8,
    num_epochs=5,
    learning_rate=5e-5
)

# Initialize trainer
trainer = DistilBertNERTraining(
    labels=labels,
    model_save_dir="drive/MyDrive/exl/model/CE",
    config=config
)

# Load pretrained model WITH CHUNK PARAMETER
trainer.load_pretrained_model(num_speakers=3, num_chunks=102)  # ADD num_chunks

# Train
trainer.train(
    train_file="drive/MyDrive/exl/data/chunk_encoding/train.txt"
)

# # Check the range of chunk_ids and speaker_ids in your training data
# import re

# chunk_ids = []
# speaker_ids = []

# with open("drive/MyDrive/exl/data/chunk_encoding/train.txt", 'r') as f:
#     for line in f:
#         line = line.strip()
#         if line and not line.startswith("-DOCSTART-"):
#             splits = line.split()
#             if len(splits) >= 4:
#                 try:
#                     chunk_ids.append(int(splits[0]))
#                     speaker_ids.append(int(splits[1]))
#                 except:
#                     pass

# print(f"Chunk IDs - Min: {min(chunk_ids)}, Max: {max(chunk_ids)}")
# print(f"Speaker IDs - Min: {min(speaker_ids)}, Max: {max(speaker_ids)}")
# print(f"Unique chunk IDs: {len(set(chunk_ids))}")
# print(f"Unique speaker IDs: {len(set(speaker_ids))}")

# Plot training loss
trainer.plot_training_loss(save_path="drive/MyDrive/exl/model/CE/training_loss.png")

# Evaluate
results, predictions = trainer.evaluate("drive/MyDrive/exl/data/chunk_encoding/test.txt", return_predictions=True)

# Results
print(results)

trainer.train_loss_history

plot_training_loss(trainer.train_loss_history)

print(predictions)

